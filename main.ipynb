{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stateless_RNN:\n",
    "    def __init__(self,n_steps = 200):\n",
    "        self.n_steps = n_steps\n",
    "        self.model = None\n",
    "        self.dataset = None        \n",
    "        self.max_id = None\n",
    "        self.tokenizer = None \n",
    "    \n",
    "    def prepare_data(self,path, batch_size = 39):\n",
    "        with open(path ,encoding=\"utf8\") as f:\n",
    "            text=f.read()\n",
    "            \n",
    "        self.tokenizer = keras.preprocessing.text.Tokenizer(char_level = True)\n",
    "        self.tokenizer.fit_on_texts([text])\n",
    "        self.max_id = len(self.tokenizer.word_index)\n",
    "    \n",
    "        [encoded] = np.array(self.tokenizer.texts_to_sequences([text])) -1\n",
    "        train_size = len(encoded) * 90//100\n",
    "        \n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "        \n",
    "        \n",
    "        window_length = self.n_steps + 1\n",
    "        self.dataset = self.dataset.window(window_length , shift =1 ,drop_remainder = True)\n",
    "        self.dataset = self.dataset.flat_map(lambda window : window.batch(window_length))\n",
    "\n",
    "        \n",
    "        self.dataset = self.dataset.shuffle(10000).batch(batch_size)\n",
    "        self.dataset = self.dataset.map(lambda windows:(windows[:,:-1] , windows[:,1:]))\n",
    "        self.dataset = self.dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=self.max_id),Y_batch))\n",
    "        self.dataset = self.dataset.prefetch(1)\n",
    "        \n",
    "    def build_layers(self):\n",
    "        self.model = keras.models.Sequential([\n",
    "        keras.layers.GRU(128, return_sequences=True, input_shape=[None,self.max_id], dropout=0.2, recurrent_dropout=0.2),\n",
    "        keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(self.max_id,activation=\"softmax\"))])\n",
    "        \n",
    "        return self.model.summary()\n",
    "\n",
    "    def train(self,epochs=5):\n",
    "        self.model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "        self.model.fit(self.dataset, epochs=epochs)\n",
    "    \n",
    "    def save_model(self,path):\n",
    "        self.model.save(path)\n",
    "        \n",
    "    def load_model(self,path):\n",
    "        self.model = keras.models.load_model(path)\n",
    "\n",
    "    \n",
    "    def preprocess_input(self,text):\n",
    "        X = np.array(self.tokenizer.texts_to_sequences(text)) -1\n",
    "        return tf.one_hot(X,depth =self.max_id)\n",
    "    \n",
    "    def predict_next_char(self,text,temperature):\n",
    "        X_new = self.preprocess_input([text])\n",
    "    \n",
    "        y_proba = self.model.predict(X_new)[0, -1:, :]\n",
    "\n",
    "        rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "\n",
    "        char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "        return self.tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "    \n",
    "    def complete_text(self,text, n_chars=200, temperature=1):\n",
    "        for _ in range(n_chars):\n",
    "            text += self.predict_next_char(text, temperature)\n",
    "        return text\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statefull_RNN:\n",
    "    def __init__(self,n_steps = 200):\n",
    "        self.n_steps = n_steps\n",
    "        self.batch_size = None\n",
    "        self.model = None\n",
    "        self.dataset = None        \n",
    "        self.max_id = None\n",
    "        self.tokenizer = None\n",
    "    \n",
    "    def prepare_data(self,path, batch_size = 1):\n",
    "        self.batch_size = batch_size\n",
    "        with open(path ,encoding=\"utf8\") as f:\n",
    "            text=f.read()\n",
    "            \n",
    "        self.tokenizer = keras.preprocessing.text.Tokenizer(char_level = True)\n",
    "        self.tokenizer.fit_on_texts([text])\n",
    "        self.max_id = len(self.tokenizer.word_index)\n",
    "    \n",
    "        [encoded] = np.array(self.tokenizer.texts_to_sequences([text])) -1\n",
    "        train_size = len(encoded) * 90//100\n",
    "                       \n",
    "        \n",
    "        window_length = self.n_steps + 1\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "        dataset = dataset.window(window_length, shift=self.n_steps,\n",
    "        drop_remainder=True)\n",
    "        dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "        dataset = dataset.batch(1)\n",
    "        dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "        dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=self.max_id), Y_batch))\n",
    "        dataset= dataset.prefetch(1)\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def build_layers(self):\n",
    "        self.model = keras.models.Sequential([keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "        dropout=0.2, recurrent_dropout=0.2,batch_input_shape=[self.batch_size, None, self.max_id]),\n",
    "        keras.layers.GRU(128, return_sequences=True, stateful=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(self.max_id, activation=\"softmax\"))\n",
    "        ])\n",
    "\n",
    "    def train(self,epochs=5):\n",
    "        self.model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "        self.model.fit(self.dataset, epochs=50, callbacks=[ResetStatesCallback()])\n",
    "\n",
    "    \n",
    "    def save_model(self,path):\n",
    "        self.model.save(path)\n",
    "        \n",
    "    def load_model(self,path):\n",
    "        self.model = keras.models.load_model(path)\n",
    "\n",
    "    \n",
    "    def preprocess_input(self,text):\n",
    "        X = np.array(self.tokenizer.texts_to_sequences(text)) -1\n",
    "        return tf.one_hot(X,depth =self.max_id)\n",
    "    \n",
    "    def predict_next_char(self,text,temperature):\n",
    "        X_new = self.preprocess_input([text])\n",
    "    \n",
    "        y_proba = self.model.predict(X_new)[0, -1:, :]\n",
    "\n",
    "        rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "\n",
    "        char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "        return self.tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "    \n",
    "    def complete_text(self,text, n_chars=200, temperature=1):\n",
    "        for _ in range(n_chars):\n",
    "            text += self.predict_next_char(text, temperature)\n",
    "        return text\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_20 (GRU)                 (None, None, 128)         68736     \n",
      "_________________________________________________________________\n",
      "gru_21 (GRU)                 (None, None, 128)         99072     \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, None, 49)          6321      \n",
      "=================================================================\n",
      "Total params: 174,129\n",
      "Trainable params: 174,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = stateless_rnn_model()\n",
    "model.prepare_data('hafez1.txt')\n",
    "model.build_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ساقی چشمت بين و من جان بينم\n",
      "\n",
      "به صوت ملک هلای توزو می‌بينم\n",
      "\n",
      "لب در سر حسن و روزی تو شد از هم\n",
      "\n",
      "گر نتورم دری\n"
     ]
    }
   ],
   "source": [
    "print(model.complete_text(text ='ساقی',n_chars=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "منزل ريا که روز و بيشت در زلف تو در سرم\n",
      "\n",
      "گر به آب جورش علم گشا از پادشهان\n",
      "چند نظمی آگه می‌زنمت خبر درد\n"
     ]
    }
   ],
   "source": [
    "print(model.complete_text(text ='من',n_chars=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "خانه را\n",
      "چرخ عشق و من از ياد که بارسان دردم\n",
      "\n",
      "شهبازی نه چندان نيست و دل غيرت می‌کنم\n",
      "\n",
      "پير مغان ببينم و می د\n"
     ]
    }
   ],
   "source": [
    "print(model.complete_text(text ='خانه',n_chars=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دوش لطف عشق می‌رود\n",
      "\n",
      "ای اميدم ز قراراتم در آن خشت و خوش\n",
      "\n",
      "من خاک سرو گفت که در جان دردی بازم\n",
      "\n",
      "دوش ماه چشم گر غمی ز صد وفا آوردم\n",
      "\n",
      "\n",
      "غزل    ۳۶۱\n",
      "\n",
      "آتش دلبر يک دو صد هر روی ره نگارم\n",
      "\n",
      "چو صباح می‌بينی و کفن عارض است\n",
      "همنم فيضی توست نيست پاکدايم\n",
      "\n",
      "چال عرش نه اين حريفان نبرد هم\n",
      "\n",
      "گر به شوق زان عذوه‌ای ز کار هم\n",
      "\n",
      "آن کو می‌نام جوی روحی چه کنم\n",
      "\n",
      "اليست چرا مذهب را که هم\n",
      "\n",
      "روز عالم نام و طلب ما هست\n",
      "مرا\n",
      "عاشقان آمده‌ای روحی تو نس\n",
      "يدادن چه عذر ناتوشم بينی بنشينم\n",
      "\n",
      "\n",
      "غزل    ۳۵۷\n",
      "\n",
      "روزگاری و مرا چون پرور عهد بشود آن ماه\n",
      "همرايت که با دلدام جان و علم زدنيست\n",
      "طربسار برخيزيم و کان در نظر ليل\n",
      "\n",
      "حافظ از ياد روان با آمده ما بسی تا می‌بينم\n",
      "\n",
      "هرگز و نظر باده از آن خاک گو می‌بينم\n",
      "\n",
      "با دل از پی آزادگان می‌کنم\n",
      "\n",
      "عرزاست که می‌گذرم هر دم به طوف\n"
     ]
    }
   ],
   "source": [
    "print(model.complete_text(text ='دوش',n_chars=700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateful_model =Statefull_RNN()\n",
    "stateful_model.prepare_data('hafez1.txt')\n",
    "stateful_model.build_layers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateful_model.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ساقی آن بهر حايت\n",
      "\n",
      "لغال  ع۲۶۲۰\n",
      "\n",
      "تا صب گران ايتوا سرحاسن قا ته خاسان\n",
      "\n",
      "سخظ حافظتمم لوی مارش کنيگوش\n",
      "\n",
      "انگ چه عاهر منيش تو بهته ما حرتان\n",
      "بخانيای شاقی خوار مخر ميوی\n",
      "صببه که می‌شدد و خل\n",
      "و دمد دود شاشافيا مض\n",
      "ديار \n"
     ]
    }
   ],
   "source": [
    "print(stateful_model.complete_text('ساقی'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
